# Database: Data Collection and Storage

This document describes how every field in the deployed bot detection database is collected and stored. The production database follows the schema in `backend/schema_bot_detection_v2.sql` plus migrations for fraud detection, grid analysis, and timing analysis.

---

## Overview

- **Database**: PostgreSQL (e.g. Cloud SQL in production).
- **Schema**: `bot_detection_v2` style with hierarchical structure **Survey → Platform → Respondent → Session**.
- **Data sources**: 
  - **API**: Session creation, event ingestion, text analysis (questions/responses), composite analysis.
  - **Webhooks**: Qualtrics/Decipher survey completion (update session with `survey_id`, `respondent_id`, `platform_id`).
  - **Client SDK**: JavaScript tracking client sends behavior events and can send question/response data; all stored via backend API.

---

## Tables and Fields

### 1. `sessions`

Stores one row per survey-taking session. Used as the root for behavior, detection, fraud, and (via session_id) survey questions/responses.

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | Generated by DB `gen_random_uuid()::text` or by app (Python `uuid.uuid4()`) when the session is created. |
| **user_agent** | TEXT | From HTTP request header `User-Agent` when `POST /api/v1/detection/sessions` is called. Sanitized via `sanitize_user_agent()`. |
| **ip_address** | VARCHAR(45) | From `request.client.host` on session creation. Validated with `is_valid_ip_address()`; set to NULL if invalid. |
| **referrer** | TEXT | From HTTP header `Referer` on session creation. |
| **created_at** | TIMESTAMPTZ | Set by DB `DEFAULT NOW()` on insert. |
| **updated_at** | TIMESTAMPTZ | Set by app on update (e.g. when session is updated). |
| **last_activity** | TIMESTAMPTZ | Set to `created_at` on insert. Updated to the timestamp of the last ingested event when `POST /api/v1/detection/sessions/{session_id}/events` is called. |
| **is_active** | BOOLEAN | Default TRUE on insert. |
| **is_completed** | BOOLEAN | Default FALSE. Set to TRUE when a Qualtrics or Decipher webhook is processed and the webhook payload contains a matching `bot_detection_session_id`; the session is then updated with survey metadata. |
| **survey_id** | VARCHAR(255) | Optional on session create (query param `survey_id`). Can be set/overwritten when the platform webhook is processed (from Qualtrics `surveyId` or Decipher equivalent). |
| **respondent_id** | VARCHAR(255) | Optional on session create (query param `respondent_id`). Set/overwritten from webhook (e.g. Qualtrics `respondentId`). |
| **platform** | VARCHAR(50) | Optional on session create (`platform`). Set to `'qualtrics'` or `'decipher'` when the corresponding webhook is processed (legacy field). |
| **platform_id** | VARCHAR(255) | Optional on session create (`platform_id` or fallback `platform`). Set from webhook `platform_id` in embedded data or default `'qualtrics'` / `'decipher'`. Used for hierarchical APIs. |
| **device_fingerprint** | TEXT | Not set on session create. Set by **FraudDetectionService** after fraud analysis: SHA256 hash from `fraud_helpers.generate_device_fingerprint(session, behavior_data)` (user_agent, screen/viewport dimensions from behavior_data, platform_id). |

**Where rows are created:** `POST /api/v1/detection/sessions` (DetectionController).  
**Where rows are updated:** Qualtrics/Decipher webhook handlers (IntegrationController) update `survey_id`, `respondent_id`, `platform`, `platform_id`, `is_completed`. Fraud detection (FraudDetectionService) updates `device_fingerprint`.

---

### 2. `behavior_data`

One row per behavioral event (keystroke, mouse, scroll, focus, etc.) in a session.

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | Generated by app (uuid) on insert. |
| **session_id** | VARCHAR(36) | Required; from the URL path when `POST /api/v1/detection/sessions/{session_id}/events` is called. Must reference an existing session. |
| **event_type** | VARCHAR(50) | From request body `event_type`. Must be one of: `keystroke`, `mouse_move`, `mouse_click`, `mouse_drag`, `scroll`, `focus`, `blur`, `page_load`, `form_submit` (see `validate_event_data()`). |
| **timestamp** | TIMESTAMPTZ | From request body `timestamp`; converted from ISO string or Unix number to datetime. |
| **created_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |
| **event_data** | JSONB | Full event payload from the client (stored as-is for the event). |
| **element_id** | VARCHAR(255) | From request body `element_id`. |
| **element_type** | VARCHAR(255) | From request body `element_type`. |
| **element_class** | VARCHAR(255) | From request body `element_class`. |
| **page_url** | TEXT | From request body `page_url`. |
| **page_title** | TEXT | From request body `page_title`. |
| **screen_width** | INTEGER | From request body `screen_width`. |
| **screen_height** | INTEGER | From request body `screen_height`. |
| **viewport_width** | INTEGER | From request body `viewport_width`. |
| **viewport_height** | INTEGER | From request body `viewport_height`. |
| **load_time** | DOUBLE PRECISION | From request body `load_time`. |
| **response_time** | DOUBLE PRECISION | From request body `response_time`. |

**Where rows are created:** `POST /api/v1/detection/sessions/{session_id}/events` (DetectionController). The client (e.g. JavaScript SDK) sends an array of events; each valid event becomes one row. Session `last_activity` is set to the last event’s timestamp.

---

### 3. `detection_results`

One row per bot detection analysis run for a session (behavioral analysis only or composite).

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | App-generated uuid on insert. |
| **session_id** | VARCHAR(36) | From the session being analyzed (URL path for analyze endpoints). |
| **is_bot** | BOOLEAN | Set by **BotDetectionEngine.analyze_session()**: TRUE if `confidence_score > 0.7`. |
| **confidence_score** | DOUBLE PRECISION | From `calculate_confidence_score(method_scores)` over the five method scores (0.0–1.0). |
| **risk_level** | VARCHAR(20) | From `determine_risk_level(confidence_score, is_bot)` — one of `'low'`, `'medium'`, `'high'`, `'critical'`. |
| **detection_methods** | JSONB | List of method names: `['keystroke_analysis','mouse_analysis','timing_analysis','device_analysis','network_analysis']`. |
| **method_scores** | JSONB | Dict of method name → score from BotDetectionEngine (keystroke, mouse, timing, device, network). |
| **processing_time_ms** | DOUBLE PRECISION | Wall-clock time (ms) for the analysis run. |
| **event_count** | INTEGER | Number of behavior_data rows analyzed. |
| **analysis_summary** | TEXT | Human-readable summary from `_generate_analysis_summary()`. |
| **flagged_patterns** | JSONB | From `_get_flagged_patterns(behavior_data, method_scores)` — patterns that contributed to the result. |
| **fraud_score** | DECIMAL(3,2) | NULL until composite analysis. Set when `POST /api/v1/detection/sessions/{session_id}/composite-analyze` runs: from composite result `fraud_score` (0.0–1.0). |
| **fraud_indicators** | JSONB | NULL until composite analysis. Set from composite result `fraud_details` (summary of fraud analysis). |
| **created_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |
| **analyzed_at** | TIMESTAMPTZ | DB default or app-set at analysis time. |

**Where rows are created:** `POST /api/v1/detection/sessions/{session_id}/analyze` (DetectionController) calls BotDetectionEngine and inserts one DetectionResult.  
**Where rows are updated:** `POST /api/v1/detection/sessions/{session_id}/composite-analyze` runs fraud analysis, then `calculate_composite_score()`; the latest detection result for the session is updated with `fraud_score` and `fraud_indicators`.

---

### 4. `survey_questions`

One row per survey question recorded for a session (used for text quality and for grid/timing analysis).

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | App-generated uuid when the question is submitted. |
| **session_id** | VARCHAR(36) | From request body `session_id` in `POST /api/v1/text-analysis/questions`. Must match an existing session. |
| **question_text** | TEXT | From request body `question_text`. |
| **question_type** | VARCHAR(50) | From request body `question_type` (e.g. `'open_ended'`, `'grid'`, `'matrix'`). |
| **element_id** | VARCHAR(255) | From request body `element_id`. |
| **element_type** | VARCHAR(50) | From request body `element_type` (e.g. `'textarea'`, `'input'`). |
| **page_url** | TEXT | From request body `page_url`. |
| **page_title** | TEXT | From request body `page_title`. |
| **asked_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |
| **created_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |

**Where rows are created:** `POST /api/v1/text-analysis/questions` (TextAnalysisController). The client (e.g. SDK or survey page) sends question metadata when a question is shown.

---

### 5. `survey_responses`

One row per submitted answer to a survey question, with optional text quality analysis (GPT-4o-mini).

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | App-generated uuid on insert. |
| **question_id** | VARCHAR(36) | From request body `question_id`; must reference an existing survey_questions.id. |
| **session_id** | VARCHAR(36) | From request body `session_id`; must match an existing session. |
| **response_text** | TEXT | From request body `response_text`. |
| **response_time_ms** | INTEGER | From request body `response_time_ms`. |
| **text_analysis_result** | JSONB | Full analysis details from **TextAnalysisService.analyze_response()** (GPT-based analysis results). |
| **quality_score** | DOUBLE PRECISION | From TextAnalysisService: overall quality 0–100. |
| **is_flagged** | BOOLEAN | From TextAnalysisService (e.g. gibberish, copy-paste, irrelevant, generic, or too short). |
| **flag_reasons** | JSONB | Dict of reason → details (e.g. confidence, reason text) from TextAnalysisService. |
| **gibberish_score** | DOUBLE PRECISION | From TextAnalysisService (0–1). |
| **copy_paste_score** | DOUBLE PRECISION | From TextAnalysisService (0–1). |
| **relevance_score** | DOUBLE PRECISION | From TextAnalysisService (0–1). |
| **generic_score** | DOUBLE PRECISION | From TextAnalysisService (0–1). |
| **created_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |
| **analyzed_at** | TIMESTAMPTZ | Set to `datetime.utcnow()` when the response is analyzed. |

**Where rows are created:** `POST /api/v1/text-analysis/responses` (TextAnalysisController). The service calls OpenAI (GPT-4o-mini) for gibberish, copy-paste, relevance, generic, and quality; all returned values are stored in the row.

---

### 6. `fraud_indicators`

One row per fraud analysis run for a session (composite-analyze or dedicated fraud endpoint).

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | App-generated uuid on insert. |
| **session_id** | VARCHAR(36) | Session being analyzed. |
| **survey_id** | VARCHAR(255) | Denormalized from session at analysis time. |
| **platform_id** | VARCHAR(255) | Denormalized from session. |
| **respondent_id** | VARCHAR(255) | Denormalized from session. |
| **ip_address** | VARCHAR(45) | From session.ip_address. |
| **ip_usage_count** | INTEGER | Count of sessions (all time) with the same IP; from FraudDetectionService._analyze_ip_address(). |
| **ip_sessions_today** | INTEGER | Count of sessions with same IP created today. |
| **ip_risk_score** | DECIMAL(3,2) | From calculate_ip_risk_score(usage_count, sessions_today). |
| **ip_country_code** | VARCHAR(2) | From geolocation lookup: fraud_helpers.extract_geolocation_from_ip(session.ip_address) → country_code (basic IP-based; production can use GeoIP). |
| **ip_city** | VARCHAR(100) | From geolocation; currently extract_geolocation_from_ip returns city=None (not implemented). |
| **device_fingerprint** | TEXT | From fraud_helpers.generate_device_fingerprint(session, behavior_data) (SHA256 of user_agent, screen/viewport, platform_id). |
| **fingerprint_usage_count** | INTEGER | Count of sessions with same device_fingerprint (FraudDetectionService._analyze_device_fingerprint). |
| **fingerprint_risk_score** | DECIMAL(3,2) | From calculate_fingerprint_risk_score(usage_count). |
| **response_similarity_score** | DECIMAL(3,2) | Max text similarity (0–1) between this session’s open-ended responses and other sessions in the same survey (difflib-based). |
| **duplicate_response_count** | INTEGER | Number of response pairs exceeding similarity threshold (e.g. 0.70). |
| **geolocation_consistent** | BOOLEAN | True if IP country is consistent with other sessions of the same respondent in the last hour; else False. |
| **geolocation_risk_score** | DECIMAL(3,2) | High (e.g. 0.9) if inconsistent; 0.0 if consistent or no IP. |
| **responses_per_hour** | DECIMAL(5,2) | Max of: sessions in last hour with same IP, same device_fingerprint, or same respondent_id. |
| **velocity_risk_score** | DECIMAL(3,2) | From calculate_velocity_risk_score(responses_per_hour). |
| **overall_fraud_score** | DECIMAL(3,2) | Weighted combination of IP, fingerprint, duplicate, geolocation, velocity (e.g. 0.25, 0.25, 0.20, 0.15, 0.15). |
| **is_duplicate** | BOOLEAN | True if overall_fraud_score >= 0.7. |
| **fraud_confidence** | DECIMAL(3,2) | Same as overall_fraud_score. |
| **flag_reasons** | JSONB | Dict of reason (e.g. ip_reuse, device_reuse, duplicate_responses, geolocation_inconsistency, high_velocity) to details (count, severity). |
| **analysis_details** | JSONB | Full sub-results: ip_analysis, fingerprint_analysis, duplicate_analysis, geolocation_analysis, velocity_analysis, processing_time_ms. |
| **created_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |

**Where rows are created:** FraudDetectionService.analyze_session_fraud() when `POST /api/v1/detection/sessions/{session_id}/composite-analyze` (or a dedicated fraud analyze endpoint) is called. Session’s device_fingerprint is updated after analysis.

---

### 7. `grid_responses`

One row per grid/matrix “cell” (or aggregated response) per question, with pattern and quality metrics.

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | App-generated uuid on insert. |
| **survey_id** | VARCHAR(255) | Denormalized from session when grid analysis is stored. |
| **platform_id** | VARCHAR(255) | Denormalized from session. |
| **respondent_id** | VARCHAR(255) | Denormalized from session. |
| **session_id** | VARCHAR(36) | Session being analyzed. |
| **question_id** | VARCHAR(36) | References survey_questions.id (question_type in ['grid','matrix']). |
| **row_id** | VARCHAR(255) | From response structure if provided; often NULL (extracted from response_dict in GridAnalysisService). |
| **column_id** | VARCHAR(255) | From response structure if provided; often NULL. |
| **response_value** | TEXT | From SurveyResponse.response_text for that question (or parsed row/column value). |
| **response_time_ms** | INTEGER | From SurveyResponse.response_time_ms. |
| **is_straight_lined** | BOOLEAN | From GridAnalysisService.detect_straight_lining() — True if >80% identical values (or similar rule). |
| **pattern_type** | VARCHAR(50) | From detect_patterns(): e.g. 'diagonal', 'reverse_diagonal', 'zigzag', 'straight_line', or NULL. |
| **variance_score** | DOUBLE PRECISION | From calculate_variance() (0–1). |
| **satisficing_score** | DOUBLE PRECISION | From calculate_satisficing_score() (0–1). |
| **created_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |
| **analyzed_at** | TIMESTAMPTZ | Set to datetime.utcnow() when analysis is stored. |

**Where rows are created:** GridAnalysisService.store_grid_analysis() after analyze_session_grid() is run (e.g. from an endpoint that triggers grid analysis for a session). Data comes from survey_questions (type grid/matrix) and their survey_responses; analysis reuses the same question’s result for all rows (straight_lining, pattern_type, variance, satisficing) per question.

---

### 8. `timing_analysis`

One row per question per session with response-time metrics and speeder/flatliner flags.

| Column | Type | How it's collected and stored |
|--------|------|------------------------------|
| **id** | VARCHAR(36) | App-generated uuid on insert. |
| **survey_id** | VARCHAR(255) | Denormalized from session when timing analysis is stored. |
| **platform_id** | VARCHAR(255) | Denormalized from session. |
| **respondent_id** | VARCHAR(255) | Denormalized from session. |
| **session_id** | VARCHAR(36) | Session being analyzed. |
| **question_id** | VARCHAR(36) | References survey_questions.id. |
| **question_time_ms** | INTEGER | From SurveyResponse.response_time_ms for that question/session. |
| **is_speeder** | BOOLEAN | True if response time &lt; threshold (e.g. too fast; TimingAnalysisService.detect_speeders()). |
| **is_flatliner** | BOOLEAN | True if response time &gt; threshold (e.g. too slow; detect_flatliners()). |
| **threshold_used** | DOUBLE PRECISION | Speeder or flatliner threshold (ms) used for this classification. |
| **anomaly_score** | DOUBLE PRECISION | Z-score from detect_timing_anomalies() (e.g. |z| &gt; 2.5 = outlier). |
| **anomaly_type** | VARCHAR(50) | e.g. 'speeder', 'flatliner', 'outlier'. |
| **created_at** | TIMESTAMPTZ | DB `DEFAULT NOW()`. |
| **analyzed_at** | TIMESTAMPTZ | Set when analysis is stored. |

**Where rows are created:** TimingAnalysisService.store_timing_analysis() after analyze_session_timing() runs (triggered by an endpoint that runs timing analysis for a session). Input is survey_responses joined to survey_questions for that session; response_time_ms drives all timing metrics.

---

## Data flow summary

| Data | Collected from | Stored via |
|------|----------------|------------|
| Session identity & metadata | Browser/API: POST /detection/sessions (headers + query params) | sessions |
| Survey/respondent/platform IDs | Webhook (Qualtrics/Decipher) or same POST params | sessions (update on webhook) |
| Behavior events | JS SDK → POST /detection/sessions/{id}/events | behavior_data |
| Bot detection result | POST /detection/sessions/{id}/analyze (engine reads behavior_data) | detection_results |
| Fraud result + session fingerprint | POST /detection/sessions/{id}/composite-analyze (reads session, behavior_data, survey_responses) | fraud_indicators; sessions.device_fingerprint |
| Composite fraud on detection | Same composite-analyze | detection_results.fraud_score, fraud_indicators |
| Question metadata | SDK/survey → POST /text-analysis/questions | survey_questions |
| Response text + text quality | SDK/survey → POST /text-analysis/responses (OpenAI) | survey_responses |
| Grid analysis | Backend: grid analysis service reads survey_questions + survey_responses | grid_responses |
| Timing analysis | Backend: timing service reads survey_responses + survey_questions | timing_analysis |

---

## Indexes (summary)

- **sessions:** survey_id, respondent_id, platform_id, created_at; composite (survey_id, platform_id, respondent_id, id), (survey_id, platform_id), (survey_id, platform_id, respondent_id); device_fingerprint.
- **behavior_data:** session_id, event_type, timestamp, created_at.
- **detection_results:** session_id, is_bot, confidence_score, risk_level, created_at.
- **survey_questions:** session_id, question_type, created_at.
- **survey_responses:** question_id, session_id, quality_score, is_flagged, created_at.
- **fraud_indicators:** session_id, survey_id, platform_id, ip_address, device_fingerprint, created_at; composites for survey, survey+platform, survey+platform+respondent, survey+platform+respondent+session; partial for is_duplicate and high risk.
- **grid_responses:** survey_id, session_id, question_id; composites for hierarchy; partial for straight_lined, pattern_type; date-filtered for recent data.
- **timing_analysis:** survey_id, session_id, question_id; composites for hierarchy; partial for speeder, flatliner; date-filtered for recent data.

---

## Migrations applied (beyond base schema)

- **add_fraud_detection_tables.sql:** Creates fraud_indicators; adds sessions.device_fingerprint; adds detection_results.fraud_score and fraud_indicators (JSONB); hierarchical columns on fraud_indicators.
- **add_grid_analysis_tables.sql:** Creates grid_responses and timing_analysis with hierarchical columns and indexes as above.

This matches the deployed database behavior for the bot detection backend and frontend.
